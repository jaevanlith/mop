defaults:
  - agent: td3
  - override hydra/launcher: submitit_local

# mode
# reward_free: false
# task settings
task: quadruped_catch
#obs_type: states             # [states, pixels]
#frame_stack: 3               # only works if obs_type=pixels
action_repeat: 1              # set to 2 for pixels
discount: 0.99
# train settings
num_train_frames: 100000    # 2M steps to converge
num_seed_frames: 10000
# eval
eval_every_frames: 1000
num_eval_episodes: 1
# pretrained
#snapshot_ts: 100000
#snapshot_base_dir: ./pretrained_models
# replay buffer
replay_buffer_size: 10
replay_buffer_num_workers: 4
batch_size: ${agent.batch_size}
nstep: ${agent.nstep}
update_encoder: false   # can be either true or false depending if we want to fine-tune encoder
# misc
seed: 1
device: cuda
save_video: true
save_train_video: false
use_tb: false
use_wandb: false
# experiment
experiment: exp
snapshot_dir: ../../snapshots/snapshot_${task}.pkl


hydra:
  run:
    dir: ./collect_quadruped/${task}-${agent.name}-${now:%m-%d-%H-%M-%S}
#    dir: ./collect/${task}-${agent.name}-medium-replay           # for collect_data_fixed, medium-replay
#    dir: ./collect/${task}-${agent.name}-expert                  # for collect_data_fixed, expert
#    dir: ./video/${task}-${agent.name}-video
  sweep:
    dir: ./exp_sweep/${now:%Y.%m.%d}/${now:%H%M}_${agent.name}_${experiment}
    subdir: ${hydra.job.num}
  launcher:
    timeout_min: 4300
    cpus_per_task: 10
    gpus_per_node: 1
    tasks_per_node: 1
    mem_gb: 160
    nodes: 1
    submitit_folder: ./exp_sweep/${now:%Y.%m.%d}/${now:%H%M}_${agent.name}_${experiment}/.slurm
