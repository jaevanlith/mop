defaults:
  - agent: pbrl                                # td3_bc, cql, pbrl
  - override hydra/launcher: submitit_local

# unsupervised exploration
# expl_agent: td3
# task settings
env: walker
tasks: [walker_walk, walker_run]                # main task to train (relable other datasets to this task)
data_type: [medium, medium-replay]              # dataset for data sharing (corresponding each share_task)

teacher_dir: ../../teacher_models/${env}

discount: 0.99
# train settings
num_grad_steps: 10
log_every_steps: 1
# eval
eval_every_steps: 1
num_eval_episodes: 1
# dataset
replay_buffer_dir: ../../collect    # make sure to update this if you change hydra run dir
replay_buffer_size: 100        # max: 10M
replay_buffer_num_workers: 4
batch_size: ${agent.batch_size}
# misc
seed: 1
device: cuda
save_video: False
use_tb: False

# used for train_offline_single
data_main: expert

wandb: True
hydra:
  run:
#    dir: ./result_td3bc_share/${task}-Share_${share_task[0]}_${share_task[1]}-Data_${data_type[0]}_${data_type[1]}-${agent.name}-${now:%m-%d-%H-%M-%S}
#    dir: ./result_cql/${task}-${data_main}-${agent.name}-${now:%m-%d-%H-%M-%S}
#    dir: ./result_pbrl/${task}-${data_main}-${agent.name}-${now:%m-%d-%H-%M-%S}
#    dir: ./result_pbrl_share/${task}-Share_${share_task[0]}_${share_task[1]}-${data_type[0]}-${agent.name}-${now:%m-%d-%H-%M-%S}
#    dir: ./output/${task}-${data_main}-${agent.name}-${now:%m-%d-%H-%M-%S}
    dir: ./result_mop/${env}-${now:%m-%d-%H-%M-%S}

